#!/usr/bin/env python3
import argparse
import os
from os.path import join
from os.path import exists
from os.path import abspath
from os.path import expanduser
import re
import random
import json

from .database_connection import DatabaseConnectionMaker
from .log_formats import colorized_logger
logger = colorized_logger('spt-cache-expressions-data-array')

from .configuration_settings import data_array_filename
from .configuration_settings import channel_lookup_filename


class CompressedMatrixPuller:
    def __init__(self, database_config_file):
        dcm = DatabaseConnectionMaker(database_config_file)
        connection = dcm.get_connection()
        self.retrieve_data_array(connection)
        connection.close()

    def get_batch_size(self):
        return 10000000

    def retrieve_data_array(self, connection):
        sparse_entries = []
        with connection.cursor() as cursor:
            cursor.execute(self.get_sparse_matrix_query())
            total = cursor.rowcount
            while cursor.rownumber < total - 1:
                current_number_stored = len(sparse_entries)
                sparse_entries.extend(cursor.fetchmany(size=self.get_batch_size()))
                logger.debug('Received %s more entries from DB.', len(sparse_entries) - current_number_stored)

        logger.debug('Received %s sparse entries total from DB.', len(sparse_entries))
        sparse_entries.sort(key = lambda x: x[0])
        logger.debug('Sorted entries by structure identifier.')
        number_cells = self.get_number_cells(sparse_entries)
        logger.debug('Unique structures: %s', number_cells)
        target_index_lookup = self.get_target_index_lookup(sparse_entries)
        logger.debug('Unique channels: %s', len(target_index_lookup))
        logger.debug('Channel index assignments: %s', target_index_lookup)

        data_array = [0] * number_cells
        logger.debug('Allocated data array.')
        self.fill_data_array(data_array, sparse_entries, target_index_lookup)
        subsample = 30
        logger.debug('%s randomly sampled vectors:', subsample)
        for i in range(subsample):
            value = data_array[random.choice(range(len(data_array)))]
            print(''.join(list(reversed(re.sub('0', ' ', f'{value:064b}')))))
        logger.debug('Sorting for consistency.')
        data_array.sort(reverse=True)
        logger.debug('Done')
        self.write_data_array_to_file(data_array)
        number_mb = int(len(data_array) * 8 / 1000000)
        parts = tuple(data_array_filename.split('.'))
        filename = '%s.0.%s' % parts
        logger.debug('Wrote %s MB to %s .', number_mb, filename)

        target_by_symbol = self.get_target_by_symbol(connection)
        self.write_channel_lookup(target_index_lookup, target_by_symbol)
        logger.debug('Wrote %s .', channel_lookup_filename)

    def get_sparse_matrix_query(self):
        return '''
        SELECT histological_structure, target, CASE WHEN discrete_value='positive' THEN 1 ELSE 0 END AS coded_value
        FROM
        expression_quantification
        ;
        '''

    def get_number_cells(self, sparse_entries_sorted):
        count = 1
        for i in range(len(sparse_entries_sorted) -1):
            if sparse_entries_sorted[i][0] != sparse_entries_sorted[i+1][0]:
                count = count + 1
        return count

    def get_target_index_lookup(self, sparse_entries_sorted):
        targets = set([])
        for i in range(len(sparse_entries_sorted)):
            targets.add(sparse_entries_sorted[i][1])
        targets = sorted(list(targets))
        lookup = {
            target : i
            for i, target in enumerate(targets)
        }
        return lookup

    def get_target_by_symbol(self, connection):
        query = '''
        SELECT identifier, symbol FROM chemical_species;
        '''
        with connection.cursor() as cursor:
            cursor.execute(query)
            rows = cursor.fetchall()
        return {
            row[1] : row[0]
            for row in rows
        }

    def fill_data_array(self, data_array, entries, target_index_lookup):
        structure_index = 0
        for i in range(len(entries)):
            if i > 0:
                if entries[i][0] != entries[i-1][0]:
                    structure_index = structure_index + 1
            if entries[i][2] == 1:
                data_array[structure_index] = data_array[structure_index] + (1 << target_index_lookup[entries[i][1]])

    def write_data_array_to_file(self, data_array):
        with open(data_array_filename, 'wb') as file:
            for entry in data_array:
                file.write(entry.to_bytes(8, 'little'))

    def write_channel_lookup(self, target_index_lookup, target_by_symbol):
        with open(channel_lookup_filename, 'wt') as file:
            file.write(json.dumps({
                'target index lookup' : target_index_lookup,
                'target by symbol' : target_by_symbol,
            }))


if __name__=='__main__':
    parser = argparse.ArgumentParser(
        description = 'Server providing counts of samples satisfying given partial signatures.'
    )
    parser.add_argument(
        '--database-config-file',
        dest='database_config_file',
        type=str,
        help='Provide the file for database configuration.',
    )
    args = parser.parse_args()
    database_config_file = abspath(expanduser(args.database_config_file))
    puller = CompressedMatrixPuller(database_config_file)

