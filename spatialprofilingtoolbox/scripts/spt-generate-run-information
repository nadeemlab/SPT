#!/usr/bin/env python3
import argparse
import os
from os.path import exists
from os.path import join
from os.path import basename

import spatialprofilingtoolbox
from spatialprofilingtoolbox.workflows import workflows
from spatialprofilingtoolbox.workflows import workflow_names

if __name__=='__main__':
    parser = argparse.ArgumentParser(
        description='''
        Create a list of core, parallelizable job specifications for a given SPT
        workflow, as well as lists of file dependencies.
        
        Note: Due to orchestration design constraints, if this script must
        depend on file contents, it can *only* depend on the contents of explicitly
        indicated files. That is, it cannot "bootstrap" and open files whose names
        are discovered by reading other files' contents.
        ''',
    )
    parser.add_argument(
        '--workflow',
        dest='workflow',
        type=str,
        choices=workflow_names,
        required=True,
    )
    parser.add_argument(
        '--file-manifest-file',
        dest='file_manifest_file',
        type=str,
        required=True,
        help='''
        Path to the file manifest file. If just a file basename, it is presumed to be
        in the current working directory, since this script is presumed to be
        deployed as a Nextflow process.
        ''',
    )
    parser.add_argument(
        '--input-path',
        dest='input_path',
        type=str,
        required=True,
        help='''Path to directory containing input data files. (For example,
        containing file_manifest.tsv).
        ''',
    )
    parser.add_argument(
        '--job-specification-table',
        dest='job_specification_table',
        type=str,
        required=True,
        help='Filename for output, job specification table CSV.',
    )
    parser.add_argument(
        '--dataset-metadata-files-list-file',
        dest='dataset_metadata_files_list_file',
        type=str,
        required=True,
        help='Filename for output, list of dataset metadata filenames.',
    )
    args = parser.parse_args()

    workflow = args.workflow
    file_manifest_file = args.file_manifest_file
    input_path = args.input_path
    job_specification_table_filename = args.job_specification_table
    dataset_metadata_files_list_file = args.dataset_metadata_files_list_file

    if not exists(file_manifest_file):
        raise FileNotFoundError(file_manifest_file)

    Generator = workflows[workflow].generator
    DatasetDesign = workflows[workflow].dataset_design
    job_generator = Generator(
        file_manifest_file=file_manifest_file,
        input_path=input_path,
        dataset_design_class=DatasetDesign,
    )
    job_generator.write_job_specification_table(job_specification_table_filename)
    job_generator.write_dataset_metadata_files_list(dataset_metadata_files_list_file)

